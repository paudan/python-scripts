<html>
    <head>
        <title>Google infrastructure for everyone else Interactions</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    </head>
    <body>Five <strong>questions</strong> for Björn <strong>Rabenstein</strong>: <strong>Insights</strong> on <strong>Kubernetes</strong>, Prometheus, and more. I recently sat down with Björn <strong>Rabenstein</strong>, <strong>production engineer</strong> at <strong>SoundCloud</strong> and co-developer of <strong><strong>Prometheus</strong></strong> , to discuss Google-inspired <strong>tools</strong> and why <strong>Kubernetes</strong> and <strong><strong>Prometheus</strong></strong> work so well together. Here are some highlights from our talk. 1. Why are <strong>Kubernetes</strong> and <strong>Prometheus</strong> such a good match? Intriguing, isn't it? The <strong>match</strong> is so good that <strong>people</strong> sometimes claim <strong>Prometheus</strong> was specifically created to <strong>monitor</strong> <strong>Kubernetes</strong> clusters. However, they were developed completely independently. Only in early 2015 did <strong>Prometheans</strong> and <strong>Kubernauts</strong> meet for the first <strong>time</strong> to connect the dots. In <strong>part</strong>, it's a <strong>case</strong> of convergent evolution. My current <strong>employer</strong> <strong>SoundCloud</strong>, where most of the initial <strong>Prometheus</strong> <strong>development</strong> happened, needed a <strong>container orchestration solution</strong> for their growing <strong>microservice architecture</strong>, and they needed to monitor all of that. No on-premise solutions were readily available, so they had to be created. Our in-house solution for container orchestration was obviously pre-Kubernetes and even pre-Docker. In <strong>view</strong> of the recent <strong>developments</strong>, we have deprecated it and are migrating to a <strong>Kubernetes</strong> setup. However, <strong>monitoring</strong> our old <strong>container orchestration system</strong> and the <strong>services</strong> running on top of it is structurally very similar to <strong>monitoring</strong> <strong>Kubernetes</strong> and the <strong>services</strong> on it. <strong>Very</strong> few <strong>steps</strong> had to be performed to come up with a native <strong>integration</strong> of <strong>Kubernetes</strong> and Prometheus. Another <strong>part</strong> of the <strong>answer</strong> to your <strong>question</strong> is what I call the shared spiritual <strong>ancestry</strong> of both, or, as a <strong>colleague</strong> phrased it: “They are <strong>twins</strong> separated at <strong>birth.” Kubernetes</strong> directly builds on <strong>Google</strong>'s decade-long <strong>experience</strong> with their own <strong>cluster scheduling system</strong>, Borg. <strong>Prometheus</strong>'s <strong>bonds</strong> to <strong><strong>Google</strong></strong> are <strong>way looser</strong> but it draws a <strong>lot</strong> of <strong>inspiration</strong> from <strong>Borgmon</strong>, the internal <strong>monitoring system</strong> <strong><strong>Google</strong></strong> came up with at about the same <strong>time</strong> as Borg. In a very sloppy <strong>comparison</strong>, you could say that <strong>Kubernetes</strong> is <strong>Borg</strong> for mere <strong>mortals</strong>, while <strong>Prometheus</strong> is <strong>Borg</strong>mon for mere <strong>mortals</strong>. Both are “second <strong>systems”</strong> trying to iterate on the <strong>good</strong> <strong>parts</strong> while avoiding the <strong>mistakes</strong> and dead <strong>ends</strong> of their ancestors. And by the <strong>way</strong>, <strong>Kubernetes</strong> and <strong>Prometheus</strong> are both <strong>Greek</strong> 10-letter words. But that is pure coincidence. My <strong>talk</strong> at <strong>Velocity Amsterdam</strong> will cover the technical <strong>aspects</strong> of pairing <strong>Prometheus</strong> with <strong>Kubernetes</strong> in more detail. Stay tuned. 2. <strong>Kubernetes</strong> and <strong>Prometheus</strong> are both <strong><strong>tools</strong></strong> that are inspired by <strong><strong>tools</strong></strong> used internally at Google. What other tools are out there? When I joined <strong>Google</strong> more than 10 <strong>years</strong> ago, it was like <strong>entering</strong> a <strong>science fiction movie</strong>, so fundamentally different was most of the technology used. The only <strong>glimpse</strong> I had taken in <strong>advance</strong> was reading the <strong>papers</strong> on <strong>MapReduce</strong> and GFS . While <strong>Google</strong> <strong>engineers</strong> certainly still live <strong>far</strong> in the <strong>future</strong>, I daresay that the <strong>tech</strong>nological <strong>differences</strong> to <strong>“normal” mid-size</strong> <strong>tech</strong> <strong>companies</strong> are much less fundamental these days. The <strong>existence</strong> of the many Google-inspired <strong>tools</strong> and <strong>technologies</strong> out there are in a <strong>way</strong> both a <strong>cause</strong> and a <strong>consequence</strong> of that development. A growing <strong>number</strong> of <strong>projects</strong> were just directly open-sourced by <strong>Google</strong>, with <strong>Kubernetes</strong> being a prime example. You can learn a <strong>lot</strong> about how <strong><strong>Go</strong>ogle</strong> works internally from <strong>technologies</strong> like <strong>protocol</strong> <strong>buffers</strong> and <strong>gRPC</strong> , and even from the <strong>Bazel</strong> <strong>build system</strong> or from the <strong>Go</strong> programming language . Another <strong>source</strong> of <strong>inspiration</strong> are the many <strong>white<strong>papers</strong> Googlers</strong> have published (like the aforementioned <strong>GFS</strong> and <strong>MapReduce</strong> <strong>papers</strong>) or just the <strong>brains</strong> of <strong>ex-Googlers</strong> that miss the <strong>awesome infrastructure</strong> after leaving the company. <strong>(</strong><strong>Rumors</strong> that <strong>Google</strong> would use Men-in-Black-style neuralyzers during offboarding are strongly exaggerated.) In that <strong>way</strong>, we got the whole <strong>Hadoop</strong> <strong>ecosystem</strong>, various other <strong>implementations</strong> of key-value <strong>stores</strong> with BigTable <strong>semantics</strong>, <strong>Zipkin</strong> and <strong>OpenTracing</strong> , or CockroachDB . In the <strong>metrics</strong> <strong>space</strong>, <strong>Prometheus</strong> deserves less credit than you might think. I see the <strong>data</strong> <strong>model</strong> used by <strong>Prometheus</strong> as the first <strong>principle</strong> from which everything else follows. That <strong>data model</strong> was brought to the <strong>world</strong> by <strong>OpenTSDB</strong> as early as 2010 (by a former <strong>teammate</strong> of mine). <strong>Prometheus “merely”</strong> added an <strong>expression language</strong> to act on the <strong>data</strong> <strong>model</strong> for <strong>graphing</strong> and alerting, and a <strong>collection path</strong> so that <strong>metrics</strong> reliably find their <strong>way</strong> from their <strong>source</strong> in the monitored <strong>targets</strong> into your monitoring system. I'm sure I have forgotten many other tools that have deserved to be mentioned here. 3. Using <strong>Kubernetes</strong> effectively requires a good <strong>understanding</strong> of new <strong>modes</strong> of <strong>application development</strong>: cloud-native <strong>practices</strong>, distributed <strong>systems</strong>, etc. What <strong>sort</strong> of <strong>mindset change</strong> is needed to make the best <strong>use</strong> of <strong>Prometheus</strong>, particularly when compared to more traditional <strong>monitoring</strong> tools? The most important <strong>paradigm shift</strong> is from <strong>hosts</strong> to services. Not only are single-host <strong>failures</strong> increasingly likely in large distributed <strong><strong>systems</strong></strong>, but those <strong><strong>systems</strong></strong> are explicitly designed to tolerate single-host <strong>failures</strong>. Waking <strong>somebody</strong> up in the <strong>middle</strong> of the <strong>night</strong> because a single host has stopped pinging is not sustainable. Your <strong>monitoring system</strong> has to be able to view the <strong>service</strong> as a whole and <strong>alert</strong> on an actual <strong>impact</strong> of the user experience. In the <strong>words</strong> of <strong>Rob Ewaschuk</strong> , symptom-based <strong>alerting</strong> is preferred over cause-based <strong>alerting</strong>. At the same time, you still need to be able to drill down to explore causes. <strong>Jamie Wilkinson</strong> nailed that pretty much in one <strong>sentence</strong>, quoting from <strong>Google</strong>'s <strong>SRE</strong> <strong>book</strong> : “We <strong>need <strong>monitoring</strong></strong> <strong>systems</strong> that allow us to alert for high-level <strong>service</strong> <strong>objectives</strong>, but retain the <strong>granularity</strong> to inspect individual <strong>components</strong> as needed.” 

 <strong>Traditional</strong> <strong>monitoring</strong> is pretty much host-based, with <strong>Nagios</strong> being the proverbial example. While you can try to bend your traditional <strong>monitoring system</strong> toward more modern <strong>ideas</strong>, you will bang your head into a wall eventually. A nice <strong>example</strong> for a post-Nagios <strong>approach</strong> toward service-based <strong>monitoring</strong> is StatsD . It was a huge step forward. However, it has certain <strong>issues</strong> concerning <strong>details</strong> of its <strong>design</strong> and <strong>implementation</strong>, but most importantly it misses out on the second half of <strong>Jamie</strong>'s <strong>sentence</strong> above: How do I go back to inspecting individual components? I’ll <strong>take</strong> that as a <strong>segue</strong> to the <strong>Prometheus</strong> data model, which I briefly touched on before. In short: Everything is labeled (as in Kubernetes— hint! ). Instead of a hierarchical <strong>organization</strong> of <strong><strong>metrics</strong></strong>, as you might know it from a typical <strong>Graphite</strong> <strong>setup</strong>, labeled <strong><strong>metrics</strong></strong> in <strong>combination</strong> with the <strong>Prometheus</strong> <strong>expression language allow</strong> you to slice and <strong>dice</strong> along the labeled dimensions at will. <strong>Metrics</strong> <strong>collection</strong> <strong><strong>happens</strong></strong> at a very basic <strong>level</strong>, <strong>aggregation</strong> and other logical <strong>processing</strong> <strong><strong>happens</strong></strong> on the <strong>Prometheus</strong> <strong>server</strong>, and can be done <strong>ad hoc</strong> , should you be in a <strong>situation</strong> where you want to view your <strong>metrics</strong> from different angles than before. Most commonly, that <strong>happens</strong> during an <strong>outage</strong> when there is really no <strong>time</strong> to reconfigure your <strong>monitoring</strong> and <strong>wait</strong> for the newly structured data to come in. Finally, you really need white-box <strong>monitoring</strong>, ideally by <strong>instrumenting</strong> your code. While the <strong>idea</strong> of <strong>black-box</strong> <strong>probing</strong> has many <strong>merits</strong>, and you should definitely have a moderate <strong>amount</strong> of <strong>black-box</strong> <strong>probing</strong> in your <strong>monitoring mix</strong>, it is not sufficient for a whole <strong>lot</strong> of reasons. Fortunately, instrumentation for Prometheus is fairly easy. <strong>Very</strong> little logic and <strong>state</strong> is required on the side of the monitored binary. As mentioned above, the <strong>logic</strong> (like <strong>calculating query</strong> <strong>rates</strong> or <strong>latency</strong> <strong>percentiles</strong>) <strong>happens</strong> later on the <strong>Prometheus</strong> server. 4. <strong>People</strong> sometimes refer to these <strong>tools</strong> as <strong>Google Infrastructure</strong> for Everyone Else (GIFEE). <strong>Google</strong> has some very unique <strong>challenges</strong>; how can one use these particular <strong>tools</strong> for their own <strong>organizations</strong>, which may not have the same <strong>issues</strong>, particularly with regard to scale? This is a fascinating topic. SoundCloud has not much more than 100 engineers. Google has more than 10,000. I would guess that similar ratios apply to the traffic served by each company. We are talking about roughly two <strong>orders</strong> of <strong>magnitude difference</strong> in scale. That's huge. Still, SoundCloud–and many other similar companies–are big enough to venture into an <strong>area</strong> where many <strong>lessons</strong> can be learned from <strong>giants</strong> like Google. You will certainly need to translate those <strong>lessons</strong> quite a <strong>bit</strong>, but the basic ideas are nevertheless applicable. <strong>Google</strong>'s <strong>book</strong> about <strong>Site Reliability Engineering</strong> is a great <strong>source</strong> of wisdom. The whole <strong>GIFEE</strong> <strong>thing</strong> made it so much simpler to put <strong>ideas</strong> from the <strong>book</strong> into concrete action. Still, you should resist the <strong>temptation</strong> to blindly copy “how <strong>Google</strong> would do it.” You need to carefully consider what's different in your <strong>organization</strong>, in <strong>terms</strong> of <strong>scale</strong>, <strong>infrastructure</strong>, workflows, <strong>culture</strong>, etc. and then decide how the underlying <strong>principle</strong> <strong>translates</strong> into concrete <strong>actions</strong> within your own framework. <strong>GIFEE</strong> gives you the <strong>tools</strong>; it's up to you to use them in <strong>ways</strong> appropriate for your organization. In <strong>case</strong> you like anecdotal <strong>evidence</strong>: It worked out quite nicely for SoundCloud. 5. You're speaking at the <strong>Velocity Conference</strong> in <strong>Amsterdam</strong> this November. What presentations are you looking forward to attending while there? <strong>Glad</strong> you asked because that made me check out the whole <strong>schedule</strong> and <strong>plan</strong> where to go in advance. On the other <strong>hand</strong> (as a true Promethean) I really hate one-dimensional <strong>metrics</strong> and picking just a few <strong>presentations</strong> from so many that are interesting for various reasons. With <strong>event</strong> logging being another important <strong>pillar</strong> of monitoring (<strong>besides metrics</strong>, what <strong>Prometheus</strong> is for), I really look forward to the two <strong>talks</strong> about using Elasticsearch for monitoring. Another topic <strong>close</strong> to my <strong>monitoring heart</strong> is a good <strong>understanding</strong> of what anomaly <strong>detection</strong> can and cannot accomplish, and I hope that <strong>Peter Buteneers</strong>'s hateful lovestory will cover that. <strong>“</strong> <strong>Unsucking</strong> your on-call <strong>experience</strong> ” and <strong>“</strong> <strong>Breaking</strong> <strong>apart</strong> a monolithic <strong>system</strong> safely without destroying your <strong>team</strong> ” are <strong>ventures</strong> <strong>SoundCloud</strong> has gone through, too, and I'm curious about the <strong>experience</strong>s of other organizations. Finally, I always enjoy Astrid Atkinson's presentations very much. I have fond <strong>memories</strong> of the very impressive <strong>onboarding session</strong> she gave to my <strong>group</strong> of <strong>Nooglers</strong> (<strong>i.e.</strong>, new <strong>Google</strong> employees) back in 2006. She is a great role model. <strong>Continue</strong> <strong>reading</strong> <strong>Google</strong> <strong>infrastructure</strong> for everyone else.</body>
</html>