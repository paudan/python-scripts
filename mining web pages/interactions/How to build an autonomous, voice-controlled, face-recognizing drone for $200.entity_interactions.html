<html>
    <head>
        <title>How to build an autonomous, voice-controlled, face-recognizing drone for $200 Interactions</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    </head>
    <body>More <strong>adventures</strong> in <strong>deep learning</strong> and cheap hardware. The <strong>goal</strong> of <strong>dimensionality reduction</strong> is to map high-dimensional <strong>data points</strong> onto a lower dimensional space. The <strong>challenge</strong> is to keep similar <strong>data points</strong> close together on the lower-dimensional mapping. As we’ll <strong>see</strong> in the next <strong>section</strong>, our <strong>data</strong> set <strong>contains</strong> 13 features. We’ll <strong>stick</strong> with two <strong>dimensions</strong> because that’s straightforward to visualize. <strong>Dimensionality reduction</strong> is often regarded as being <strong>part</strong> of the exploring step. It’s useful for when there are too many features for plotting. You could do a <strong>scatter plot matrix</strong>, but that only shows you two <strong>features</strong> at a time. <strong>It’s</strong> also useful as a <strong>preprocessing step</strong> for other machine-learning algorithms. Most <strong>dimensionality reduction</strong> <strong>algorithms</strong> are unsupervised, which means that they don’t employ the <strong>labels</strong> of the <strong>data points</strong> in <strong>order</strong> to construct the lower-dimensional mapping. <strong>Continue</strong> <strong>reading</strong> How to build an autonomous, voice-controlled, face-recognizing drone for $200 .</body>
</html>