<html>
    <head>
        <title>Building enterprise data applications with open source components Interactions</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    </head>
    <body><strong>Subscribe</strong> to the O'Reilly <strong>Data Show Podcast</strong> to explore the <strong>opportunities</strong> and <strong>techniques</strong> driving big <strong><strong>data</strong></strong> and <strong><strong>data</strong></strong> science. I first found myself having to learn <strong>Scala</strong> when I started using <strong>Spark (</strong>version 0.5). Prior to <strong>Spark</strong>, I'd peruse <strong>books</strong> on <strong>Scala</strong> but just never found an excuse to delve into it. In the early <strong>days</strong> of <strong>Spark</strong>, <strong>Scala</strong> was a necessity — I quickly came to appreciate it and have continued to use it enthusiastically. For this <strong>Data Show Podcast</strong>, I spoke with O'Reilly <strong>author</strong> and <strong>Typesafe</strong>'s <strong>resident</strong> big <strong><strong>data</strong></strong> <strong>architect</strong> <strong>Dean Wampler</strong> about <strong>Scala</strong> and other <strong>programming</strong> <strong>languages</strong>, the big <strong><strong>data</strong></strong> <strong>ecosystem</strong>, and his recent <strong>interest</strong> in real-time applications. Dean has <strong><strong>years</strong></strong> of <strong>experience</strong> helping <strong>companies</strong> with large <strong>software</strong> <strong>projects</strong>, and over the last several <strong><strong>years</strong></strong>, he's focused primarily on helping <strong>enterprises</strong> <strong>design</strong> and build big data applications. Here are a few <strong>snippets</strong> from our <strong>conversation</strong>:
 
 <strong>Apache Mesos</strong> & the big <strong>data</strong> <strong>ecosystem</strong> 
 It's a very nice <strong>capability</strong> [of Spark] that you can actually run it on a <strong>laptop</strong> when you're developing or working with smaller <strong>data</strong> sets. <strong>…</strong> But, of <strong>course</strong>, the real <strong>interesting part</strong> is to run on a cluster. You need some cluster infrastructure and, fortunately, it works very nicely with YARN. It works very nicely on the Hadoop ecosystem. <strong>…</strong> The nice <strong>thing</strong> about <strong>Mesos</strong> over <strong>YARN</strong> is that it's a much more flexible, capable resource manager. It basically treats your <strong>cluster</strong> as one giant <strong>machine</strong> of <strong>resources</strong> and gives you that <strong>illusion</strong>, ignoring <strong>things</strong> like <strong>network</strong> <strong>latencies</strong> and stuff. You're just working with a giant <strong>machine</strong> and it allocates <strong>resources</strong> to your <strong><strong>jobs</strong></strong>, multiple <strong>users</strong>, all that <strong>stuff</strong>, but because of its greater <strong>flexibility</strong>, it cannot only run <strong>things</strong> like <strong>Spark</strong> <strong><strong>jobs</strong></strong>, it can run <strong>services</strong> like <strong>HDFS</strong> or <strong>Cassandra</strong> or <strong>Kafka</strong> or any of these tools. <strong>…</strong> What I saw was there was a <strong>situation</strong> here where we had maybe a <strong>successor</strong> to YARN. It's obviously not as <strong>mature</strong> an <strong><strong>ecosystem</strong></strong> as the <strong>Hadoop</strong> <strong><strong>ecosystem</strong></strong> but not <strong>everybody</strong> needs that maturity. Some <strong>people</strong> would rather have the <strong>flexibility</strong> of <strong>Mesos</strong> or of solving more focused problems. <strong>Tachyon</strong> 
 I think it's still early <strong>days</strong>, but I think the potential is there. In a <strong>way</strong>, it's analogous to <strong>Spark</strong> in that it starts with some really good <strong>fundamental</strong> ideas and then builds on them. In <strong>Spark</strong>'s <strong>case</strong>, it would be the so-called <strong>resilient</strong> distributed data sets. With <strong>Tachyon</strong>, it's basically an in-memory distributed <strong>file <strong>system</strong></strong> — or a <strong>way</strong> to think of it, it's like a distributed <strong>cache</strong> with <strong>file <strong>system</strong></strong> semantics. What's attractive about that is that you can basically have multiple <strong>applications</strong> accessing the same <strong>data sets</strong> and <strong>memory</strong>, accessing them through a <strong>file system</strong>, <strong>kind</strong> of <strong><strong>API</strong></strong> or a more proprietary <strong><strong>API</strong></strong>, but you get in-<strong>memory</strong> <strong>speeds</strong> with some <strong>configuration</strong> to do some durability. Behind the <strong>scenes</strong>, obviously you don't want that <strong>data</strong> to get lost if the machine goes down. There's <strong>facilities</strong> for having the <strong><strong>data</strong></strong> be backed to a <strong>file system</strong>, so I think it solves a <strong>number</strong> of interesting <strong>problems</strong> in big <strong><strong>data</strong></strong> applications like sharing <strong><strong>data</strong></strong> between running <strong>jobs</strong>, like <strong>giving</strong> you much more <strong>flexibility</strong> and <strong>performance</strong> characteristics. I think it's pretty exciting. <strong><strong>Backpressure</strong></strong> and reactive <strong>streams</strong> 
 <strong><strong>Backpressure</strong></strong> would be signaling from the <strong>consumer</strong> back to the <strong>producer</strong>, 'Hey, I can't take as much <strong>data</strong> as you're feeding me, or I can actually take more <strong>data</strong>.' It's this <strong>protocol</strong> for controlling the <strong>rate</strong> of flow. And the <strong>reason</strong> this is important is because a classic <strong>way</strong> of implementing a <strong>connection</strong> between a <strong>producer</strong> and <strong>consumer</strong> is to put a <strong>buffer</strong>, like a <strong>queue</strong> in between them but then you have this dilemma. You could make it unbounded so that you never fill it up but the problem is memory is finite. Inevitably when you think about what's going to happen in a <strong>stream system</strong> that runs for <strong>years</strong>, some weird <strong>situation</strong> … where the <strong>producer</strong> will just keep feeding <strong>data</strong> too fast to a <strong>consumer</strong> and it'll eventually run out of <strong>memory</strong> and crash. You don't like that but the <strong>flipside</strong> is, all <strong>right</strong>, make these <strong>things</strong> bounded <strong>buffers</strong> but you still haven't completely solved your problems because then what do you do when that fills up? You end up arbitrarily dropping data or doing some other thing. ... The <strong>idea</strong> with <strong>backpressure</strong> is, just have a <strong>negotiation happen</strong> out of <strong>band</strong>, like separate <strong>socket connection</strong> or <strong>something</strong>, where when the <strong>consumer</strong> can keep up, it's just a push model. I just keep pushing <strong>data</strong>, but if the <strong><strong>consumer</strong></strong> gets backed up, then the <strong><strong>consumer</strong></strong> can signal, 'All <strong>right</strong>, <strong>send</strong> me five more or <strong>send</strong> me 10 more,' or whatever, that <strong>kind</strong> of <strong>thing</strong>, until <strong>[</strong>it] gets caught up. <strong>[</strong> <strong>Reactive</strong> <strong>streams</strong> ] is a standard for that <strong>backpressure mechanism</strong> <strong>[</strong>so that] if you get a directed <strong>graph</strong> of these <strong>things</strong>, then you can make strategic <strong>decisions</strong> at the beginning. If I've got <strong>data</strong> coming into this <strong>system</strong>  and I'm getting <strong>backpressure</strong>, at least I can make a strategic decision about what to do. <strong>Subscribe</strong> to the O'Reilly Data Show Podcast 
 Stitcher , <strong>TuneIn</strong> , <strong>iTunes</strong> , <strong>SoundCloud</strong> , RSS 
 
 
 Related <strong>resources</strong>: 
 
 Why the <strong>data</strong> <strong>center</strong> needs an <strong>operating system</strong> by <strong>Benjamin Hindman</strong>, <strong>creator</strong> of Apache Mesos 
 Introduction to <strong>Tachyon</strong> and a <strong>deep dive</strong> into <strong>Baidu</strong>'s <strong>production use case</strong> : a recent O'Reilly <strong>webcast</strong> co-presented by <strong>Haoyuan Li</strong>, the co-<strong>creator</strong> of <strong>Tachyon</strong>. Showcasing the real-time <strong>processing revival</strong>: <strong>Tools</strong> and learning <strong>resources</strong> for <strong>building intelligent</strong>, real-time <strong>products</strong> (<strong>sessions</strong> at Strata+Hadoop World NYC) 
 Apache <strong>Spark</strong>: <strong>Powering</strong> <strong>applications</strong> on-premise and in the <strong>cloud</strong> , a <strong>Data Show</strong> <strong>episode</strong> featuring <strong>Spark</strong>'s <strong>release manager</strong>, Patrick Wendell. You can listen to our entire <strong>interview</strong> in the <strong><strong>SoundCloud</strong></strong> <strong>player</strong> above, or subscribe through <strong>Stitcher</strong> , <strong><strong>SoundCloud</strong></strong> , <strong>TuneIn</strong> , or iTunes . <strong>Image</strong> on <strong>article</strong> and <strong>category</strong> <strong>pages</strong> by <strong>L Rempe-Gillen</strong> on Wikimedia Commons .</body>
</html>