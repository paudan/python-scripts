<html>
    <head>
        <title>How to build an autonomous, voice-controlled, face-recognizing drone for $200 Summary</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    </head>
    <body><p>More adventures in deep learning and cheap hardware. <strong>The goal of dimensionality reduction is to map high-dimensional data points onto a lower dimensional space.</strong> <strong>The challenge is to keep similar data points close together on the lower-dimensional mapping.</strong> <strong>As we’ll see in the next section, our data set contains 13 features.</strong> We’ll stick with two dimensions because that’s straightforward to visualize. 

 Dimensionality reduction is often regarded as being part of the exploring step. It’s useful for when there are too many features for plotting. You could do a scatter plot matrix, but that only shows you two features at a time. It’s also useful as a preprocessing step for other machine-learning algorithms. <strong>Most dimensionality reduction algorithms are unsupervised, which means that they don’t employ the labels of the data points in order to construct the lower-dimensional mapping.</strong> <strong>Continue reading How to build an autonomous, voice-controlled, face-recognizing drone for $200 .</strong></p></body>
</html>